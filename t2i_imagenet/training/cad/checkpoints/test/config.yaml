model:
  optimizer:
    optim:
      _target_: utils.optimizers.Lamb
      lr: 0.001
      betas:
      - 0.9
      - 0.999
      weight_decay: 0.01
    exclude_ln_and_biases_from_weight_decay: true
  lr_scheduler:
    _partial_: true
    _target_: utils.lr_scheduler.WarmupCosineDecayLR
    warmup_steps: 5000
    total_steps: ${trainer.max_steps}
    rate: 0.7
  network:
    _target_: models.networks.rin.RINTextCond
    data_size: ${data.data_resolution}
    data_dim: 256
    num_input_channels: 4
    num_latents: 128
    latents_dim: 768
    label_dim: ${data.label_dim}
    num_cond_tokens: ${data.num_cond_tokens}
    num_processing_layers: 4
    num_blocks: 4
    path_size: 2
    read_write_heads: 16
    compute_heads: 12
    latent_mlp_multiplier: 4
    data_mlp_multiplier: 4
    rw_dropout: 0.0
    compute_dropout: 0
    rw_stochastic_depth: 0
    compute_stochastic_depth: 0
    time_scaling: 1000.0
    noise_embedding_type: positional
    data_positional_embedding_type: learned
    weight_init: xavier_uniform
    bias_init: zeros
    use_cond_token: true
    use_biases: true
    concat_cond_token_to_latents: false
    use_cond_rin_block: true
    num_text_registers: 16
    use_16_bits_layer_norm: false
  train_noise_scheduler:
    _target_: models.schedulers.LinearScheduler
    start: 1
    end: 0
    clip_min: 1.0e-09
  inference_noise_scheduler:
    _target_: models.schedulers.CosineSchedulerSimple
    ns: 0.0002
    ds: 0.00025
  preconditioning:
    _target_: models.preconditioning.DDPMPrecond
    num_latents: ${model.network.num_latents}
    latents_dim: ${model.network.latents_dim}
  data_preprocessing:
    _target_: models.preprocessing.PrecomputedSDLatentPreconditioning
    input_key_mean: ${model.vae_embedding_name_mean}
    input_key_std: ${model.vae_embedding_name_std}
    output_key_root: x_0
    vae_sample: true
    channel_wise_normalisation: ${model.channel_wise_normalisation}
  cond_preprocessing:
    _target_: models.preprocessing.PrecomputedTextConditioning
    input_key: flan_t5_xl
    output_key_root: text_tokens
    drop_labels: false
  postprocessing:
    _target_: models.postprocessing.SD1_5VAEDecoderPostProcessing
    vae:
      _target_: diffusers.AutoencoderKL.from_pretrained
      pretrained_model_name_or_path: benjamin-paine/stable-diffusion-v1-5
      local_files_only: true
      subfolder: vae
    channel_wise_normalisation: ${model.channel_wise_normalisation}
  loss:
    _partial_: true
    _target_: models.losses.DDPMLoss
    self_cond_rate: 0.9
    cond_drop_rate: 0.1
    conditioning_key: ${model.cond_preprocessing.output_key_root}
    resample_by_coherence: false
    sample_random_when_drop: false
  val_sampler:
    _partial_: true
    _target_: models.samplers.ddim.ddim_sampler
    num_steps: 250
    cfg_rate: ${model.cfg_rate}
  test_sampler:
    _partial_: true
    _target_: models.samplers.ddpm.ddpm_sampler
    num_steps: 1000
    cfg_rate: ${model.cfg_rate}
  uncond_conditioning:
    _target_: numpy.load
    file: ${root_dir}/t2i_imagenet/training/cad/utils/flan_t5_xl_uncond.npy
  text_embedding_name: flan_t5_xl
  return_text: true
  vae_embedding_name_mean: vae_embeddings_mean_${data.img_resolution}
  vae_embedding_name_std: vae_embeddings_std_${data.img_resolution}
  return_image: true
  channel_wise_normalisation: false
  cutmix:
    do_cutmix: false
    do_cutmix_above_threshold_prob: null
    cutmix_noise_threshold_ratio: null
  name: RIN
  ema_decay: 0.9999
  start_ema_step: 0
  cfg_rate: 8.0
computer:
  devices: 1
  num_workers: 10
  progress_bar_refresh_rate: 2
  sync_batchnorm: false
  accelerator: gpu
  precision: 16-mixed
  strategy: auto
  num_nodes: 1
  eval_gpu_type: v100
data:
  train_aug:
    _target_: torchvision.transforms.Compose
    transforms:
    - _target_: torchvision.transforms.ToTensor
    - _target_: utils.image_processing.CenterCrop
      ratio: '1:1'
    - _target_: torchvision.transforms.Resize
      size: ${data.img_resolution}
      interpolation: 3
      antialias: true
    - _target_: torchvision.transforms.RandomHorizontalFlip
      p: 0.5
    - _target_: torchvision.transforms.Normalize
      mean: 0.5
      std: 0.5
  val_aug:
    _target_: torchvision.transforms.Compose
    transforms:
    - _target_: torchvision.transforms.ToTensor
    - _target_: utils.image_processing.CenterCrop
      ratio: '1:1'
    - _target_: torchvision.transforms.Resize
      size: ${data.img_resolution}
      interpolation: 3
      antialias: true
    - _target_: torchvision.transforms.Normalize
      mean: 0.5
      std: 0.5
  name: ImageNet_256_Text_LDM
  type: text_conditional
  img_resolution: 256
  data_resolution: 32
  label_dim: 2048
  num_cond_tokens: 77
  full_batch_size: 128
  in_channels: 4
  out_channels: 4
  train_instance:
    _partial_: true
    _target_: data.text_dataset.TextWebDataset
    root: ${data_dir}/train
    image_transforms: ${data.train_aug}
    train: true
    text_embedding_name: ${model.text_embedding_name}
    vae_embedding_name_mean: ${model.vae_embedding_name_mean}
    vae_embedding_name_std: ${model.vae_embedding_name_std}
    return_image: ${model.return_image}
    return_text: ${model.return_text}
    min_image_size: ${data.img_resolution}
  val_instance:
    _partial_: true
    _target_: data.text_dataset.TextDataset
    root: ${data_dir}/val
    image_transforms: ${data.val_aug}
    text_embedding_name: ${model.text_embedding_name}
    vae_embedding_name_mean: ${model.vae_embedding_name_mean}
    vae_embedding_name_std: ${model.vae_embedding_name_std}
    return_image: ${model.return_image}
    return_text: ${model.return_text}
  target_transform:
    _target_: utils.one_hot_transform.OneHotTransform
    num_classes: ${data.label_dim}
  collate_fn:
    _target_: data.datamodule.dict_collate_and_pad
    keys_to_pad:
    - flan_t5_xl
    max_length: 256
  train_dataset: ${data.train_instance}
  val_dataset: ${data.val_instance}
  datamodule:
    _target_: data.datamodule.WebdatasetDataModule
    train_dataset: ${data.train_dataset}
    val_dataset: ${data.val_dataset}
    full_batch_size: ${data.full_batch_size}
    num_workers: ${computer.num_workers}
    collate_fn: ${data.collate_fn}
    num_nodes: ${computer.num_nodes}
    num_devices: ${computer.devices}
trainer:
  _target_: pytorch_lightning.Trainer
  max_steps: 100000
  val_check_interval: 5000
  check_val_every_n_epoch: null
  devices: ${computer.devices}
  accelerator: ${computer.accelerator}
  strategy: ${computer.strategy}
  log_every_n_steps: 1
  num_nodes: ${computer.num_nodes}
  precision: ${computer.precision}
  gradient_clip_val: 2.0
logger:
  _target_: pytorch_lightning.loggers.WandbLogger
  save_dir: ${root_dir}/t2i_imagenet/training/cad/wandb
  name: ${experiment_name}
  project: Captioner Diffusion
  log_model: false
  offline: true
checkpoints:
  _target_: callbacks.checkpoint_and_validate.ModelCheckpointValidate
  gpu_type: ${computer.eval_gpu_type}
  validate_when_not_on_cluster: false
  validate_when_on_cluster: false
  eval_set: val
  validate_conditional: true
  validate_unconditional: false
  validate_per_class_metrics: false
  shape:
  - ${model.network.num_input_channels}
  - ${data.data_resolution}
  - ${data.data_resolution}
  num_classes: ${data.label_dim}
  dataset_name: ${data.name}
  dirpath: ${root_dir}/t2i_imagenet/training/cad/checkpoints/${experiment_name}
  filename: step_{step}
  monitor: val/loss_ema
  save_last: true
  save_top_k: -1
  enable_version_counter: false
  every_n_train_steps: 25000
  auto_insert_metric_name: false
progress_bar:
  _target_: pytorch_lightning.callbacks.TQDMProgressBar
  refresh_rate: ${computer.progress_bar_refresh_rate}
data_dir: /home/lucas/geovic_all_mount/imagenet_webdataset
root_dir: ${hydra:runtime.cwd}
sana_size: null
experiment_name_suffix: base
experiment_name: test
